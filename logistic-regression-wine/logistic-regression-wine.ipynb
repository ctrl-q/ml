{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c433b63-8702-4d46-a0b0-0c9c2db86e13",
    "_uuid": "3884d273363bb16449da10e7d9bc4ac6cdb9dcb9",
    "collapsed": true
   },
   "source": [
    "# 1. Exploratory Analysis\n",
    "### We will visualize the data, in order to understand its structure & distribution, and build a model that makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4af0f1fc29dfc43951f385421651d8d00c085b0c"
   },
   "source": [
    "### The dataset is comprised of 1599 red wines and 4898 white wines, split into 2 csv files. We will first merge the 2 datasets and include a binary variable is_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d564862fdfa3314478f16b7fba3d792e20d0b64"
   },
   "outputs": [],
   "source": [
    "DIR = \"input\" # location of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2cb5b0e9c58e0d154661d53d4ec3aa356442471"
   },
   "outputs": [],
   "source": [
    "data_red = pd.read_csv(join(DIR, \"winequality-red.csv\"), delimiter=\";\")\n",
    "data_white = pd.read_csv(join(DIR, \"winequality-white.csv\"), delimiter=\";\")\n",
    "data_red[\"is_red\"] = 1\n",
    "data_white[\"is_red\"] = 0\n",
    "\n",
    "data = pd.concat((data_red, data_white))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb996186a2da99590b5e1faf2bbac0cdbf75acce"
   },
   "source": [
    "### Let's find correlations between dimensions, to potentially remove irrelevant ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "235fef65-fbd8-423f-bda2-c646e7fa5b31",
    "_kg_hide-output": true,
    "_uuid": "30fa2868d4b06a878847a8286656277557ceae2c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a6671fa53fa9c287590c1a006fd32fe045b0b6b"
   },
   "source": [
    "Some relatively strong correlations:\n",
    "* free and total sulfur dioxides (expected since total depends on free)\n",
    "* sulfur dioxides and is_red (also expected as that partly defines red & white wines)\n",
    "\n",
    "Nothing really surprising here. Some of these variables may potentially be dropped if found to be irrelevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ea7b8118871d93e091e2065a9fa555695eed822"
   },
   "source": [
    "### Let's now check if there are notable differences between red & white wine qualities.\n",
    "### Here's the distribution of wine quality by wine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4690bf97-d84e-441e-bb71-3254fb08df3f",
    "_uuid": "1d7b88f182da62cc909f5cdce6a322fa826b2cfb"
   },
   "outputs": [],
   "source": [
    "data.hist(column=\"quality\", by=data[\"is_red\"], density=True, range=(0,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18fe61c50b5131f6e3383958d19ab07d640ba9ac"
   },
   "source": [
    "We can see the disributions are similar between wine qualities, with most wines being mediocre (as expected) <br>\n",
    "Looks normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e4f266ae9f81b7d633e41eea5e168c433938d91"
   },
   "source": [
    "### Let's make sure our dataset is balanced by looking at possible outliers.\n",
    "To do so, we will look at the boxplot of each dimension with respect to wine quality. <br>\n",
    "It will give us an idea of the range and variability of features, as well their possible outliers <br>\n",
    "\n",
    "The boxplot will split values in quartiles delimited by horizontal lines. Points far away from can be considered outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "749b0e5c70b95c9808fd334094ab4982414461cf"
   },
   "outputs": [],
   "source": [
    "boxplots = plt.figure(figsize=(12,24))\n",
    "for i, dim in enumerate(data): \n",
    "    if i < 10:  # no need for boxplot of wine type or wine qualities\n",
    "        boxplots.add_subplot(5, 2, i+1)\n",
    "        sns.boxplot(x=\"quality\", y=dim, data=data, hue=\"is_red\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7da96e162a532664f90db5de195d6d9515897bc"
   },
   "source": [
    "Some categories (like fixed & volatile acidities) have many points located above the interquartile range, but not by much. Most variables have a few noticeable outliers.\n",
    "\n",
    "Residual sugars, sulphates and chlorides have relatively high variance, by looking at their interquartile ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb28824414f9348dddcc647739da5bef54957da9"
   },
   "source": [
    "# 2. Preprocessing\n",
    "### We will now get our data ready for prediction, and try to optimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19834b0915b6c7c3040a302debe6f5cd96767018"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "5dbb983cb8cfdaa61a7dee7a1da8e77aaac4fbfb"
   },
   "outputs": [],
   "source": [
    "# Separate target from dimensions, and remove high-variance columns\n",
    "X_red = data_red.copy().drop(columns=[\"quality\", \"is_red\", \"chlorides\", \"residual sugar\", \"sulphates\"])\n",
    "y_red = data_red[\"quality\"]\n",
    "\n",
    "X_white = data_white.copy().drop(columns=[\"quality\", \"is_red\", \"chlorides\"])\n",
    "y_white = data_white[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43c2e4ee7889938ea8f7132d3de35376cbe0643f"
   },
   "outputs": [],
   "source": [
    "# Drop missing values, if any\n",
    "if sum(data.isna().sum()) == 0:\n",
    "    print(\"No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc3b161863234cc24a79191a2b1452738b5a0db2"
   },
   "source": [
    "### Rescale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "782b08021378c0e0666bea1fa400128b8e2ac359"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler # resistant to data that has few large outliers\n",
    "X_red = RobustScaler().fit_transform(X_red)\n",
    "X_white = RobustScaler().fit_transform(X_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04aa7a4c-a2b7-4aaa-b6a8-906276a98b7e",
    "_uuid": "d5ddcda32e5eccd3ddf2cc0acf0cb4cca2c7a92b"
   },
   "source": [
    "### PCA decomposition for removal of redundant features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "60033c46-14bf-4037-bf32-49c6288affdc",
    "_uuid": "3d91581ba034a1dfb52313a7c652c67ee0f48f29"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_red_PCA = PCA(0.95, random_state=SEED).fit_transform(X_red) # reduce dimensionality while keeping 95% of explained variance\n",
    "X_white_PCA = PCA(0.95, random_state=SEED).fit_transform(X_white) # reduce dimensionality while keeping 95% of explained variance\n",
    "\n",
    "print(\"PCA removed\", X_red.shape[1] - X_red_PCA.shape[1], \"dimensions from the red wine dataset\")\n",
    "print(\"PCA removed\", X_white.shape[1] - X_white_PCA.shape[1], \"dimensions from the white wine dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ab3c7405-baa0-4c4b-9a92-661d7fdb0ce5",
    "_uuid": "3fce7c0912fdfec6b4fd6d1faba303c8a297a105"
   },
   "source": [
    "# 3. Logistic Regression\n",
    "### We will run a regularized logistic regression in both the original and reduced input spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f22ed00e4cadbb3257a19489a83663a131344153"
   },
   "outputs": [],
   "source": [
    "n_jobs = -1 # Set this to the max. number of CPU cores to be used (-1 for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "260afad9191ac10e2e1ae928f541255053743001"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def logistic_regression(X_input, y_input, degrees=[1]):\n",
    "    accuracies = [-1]*(max(degrees)+1)\n",
    "    best_predictions = best_conf_matrix = None\n",
    "\n",
    "    for degree in degrees:\n",
    "        clf = LogisticRegressionCV(Cs=[1, 1/10, 1/100, 1/1000, 1/10000, 1/100000], # Test different C values, equal to 1/lambda\n",
    "                               cv=4,\n",
    "                               max_iter=100000 if max(degrees) >= 4 else 1000,\n",
    "                               n_jobs=n_jobs,\n",
    "                               multi_class=\"multinomial\",\n",
    "                               random_state=SEED\n",
    "                              )\n",
    "        X_input = PolynomialFeatures(degree).fit_transform(X_input)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_input, y_input,\n",
    "                                                    stratify=y_input/len(y_input), # stratify to preserve distribution\n",
    "                                                    random_state=SEED\n",
    "                                                   )                \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        predictions = clf.predict(X_test)\n",
    "        conf_matrix = confusion_matrix(y_test, predictions)\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        if acc > max(accuracies):\n",
    "            best_predictions, best_conf_matrix = predictions, conf_matrix\n",
    "        accuracies[degree] = acc\n",
    "\n",
    "    return best_predictions, best_conf_matrix, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "933636fbfd7928830b2586a3e777bb9a88388106"
   },
   "outputs": [],
   "source": [
    "# Here are the results you should get after running the regression\n",
    "# We show these so you know the best polynomial degree for each dataset\n",
    "\n",
    "acc_X_red = [-1, 0.5825, 0.5725, 0.57, 0.555]\n",
    "acc_X_red_PCA = [-1, 0.565, 0.5775, 0.56, 0.555]\n",
    "acc_X_white = [-1, 0.5371428571428571, 0.566530612244898, 0.583673469, 0.6]\n",
    "acc_X_white_PCA = [-1, 0.5338775510204081, 0.5624489795918367, 0.572244898, 0.582857143]\n",
    "degrees = [1, 2, 4, 4]\n",
    "\n",
    "# Feel free to change the degrees argument for the function calls below\n",
    "\n",
    "pred_X_red, conf_X_red, acc_X_red = logistic_regression(X_red, y_red, [degrees[0]])\n",
    "pred_X_PCA_red, conf_X_PCA_red, acc_X_red_PCA = logistic_regression(X_red_PCA, y_red, [degrees[1]])\n",
    "pred_X_white, conf_X_white, acc_X_white = logistic_regression(X_white, y_white, [degrees[2]])\n",
    "pred_X_PCA_white, conf_X_PCA_white, acc_X_white_PCA = logistic_regression(X_white_PCA, y_white, [degrees[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5eede0af35edfa5c331efe3efbadcf9fd9b91cc1"
   },
   "source": [
    "Let's compare the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cba7613e73e0fe30d5535ca52844edc0d15b625"
   },
   "outputs": [],
   "source": [
    "title = \"Regression accuracy on red wines\"\n",
    "print(title)\n",
    "print(\"-\"*len(title))\n",
    "print(\"Before PCA:\", round(max(acc_X_red)*100, 2), \"%.\", \"Polynomial degree\", acc_X_red.index(max(acc_X_red)))\n",
    "print(\"After PCA:\", round(max(acc_X_red_PCA)*100, 2), \"%.\", \"Polynomial degree\", acc_X_red_PCA.index(max(acc_X_red_PCA)))\n",
    "print()\n",
    "mode = y_red.mode().sum()\n",
    "print(\"Accuracy of constant predictor:\", round((y_red == mode).sum()*100/len(y_red), 2), \"%\")\n",
    "\n",
    "random_pred = np.random.permutation(y_red)\n",
    "print(\"Accuracy of random chance:\", round((y_red == random_pred).sum()*100/len(y_red), 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1886013f6763078074d09b2d576f519ec43cf26d"
   },
   "outputs": [],
   "source": [
    "title = \"Regression accuracy on white wines\"\n",
    "print(title)\n",
    "print(\"-\"*len(title))\n",
    "print(\"Before PCA:\", round(max(acc_X_white)*100, 2), \"%.\", \"Polynomial degree\", acc_X_white.index(max(acc_X_white)))\n",
    "print(\"After PCA:\", round(max(acc_X_white_PCA)*100, 2), \"%.\", \"Polynomial degree\", acc_X_white_PCA.index(max(acc_X_white_PCA)))\n",
    "print()\n",
    "mode = y_white.mode().sum()\n",
    "print(\"Accuracy of constant predictor:\", round((y_white == mode).sum()*100/len(y_white), 2), \"%\")\n",
    "\n",
    "random_pred = np.random.permutation(y_white)\n",
    "print(\"Accuracy of random chance:\", round((y_white == random_pred).sum()*100/len(y_white), 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "670afc0db549655e868d2d0a27f8a1aae191e234"
   },
   "source": [
    "Not impressive.\n",
    "\n",
    "PCA has brought little to no value. This could be due to its linear nature. <br>\n",
    "Polynomial mappings also did not improve performance by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fa9d5b350229a0ed0ece217a2613249168349f6"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55039408401b94e252540c91f28918667d1f1d08"
   },
   "outputs": [],
   "source": [
    "confs = plt.figure(figsize=(16, 6))\n",
    "confs.add_subplot(1, 2, 1)\n",
    "plot_confusion_matrix(conf_X_red, classes=np.unique(y_red), title=\"Confusion matrix for red wines\")\n",
    "confs.add_subplot(1, 2, 2)\n",
    "plot_confusion_matrix(conf_X_white, classes=np.unique(y_white), title=\"Confusion matrix for white wines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "572d356903cf450d3bd1794a0cde81431d6431a5"
   },
   "source": [
    "# Extra: Concatenating the datasets & re-constructing the target\n",
    "### We saw that the value of quality is mainly split into 4 values. Let's see if grouping would help performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac65cb1efeffdf053d868f3aaef041c8ad59cf7d"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(data[\"quality\"], return_counts=True)\n",
    "print(\"Distribution of wine quality\")\n",
    "dict(zip(unique, counts*100.0/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18ed81e3a49cdd3bbbb914cdf13b91d228512dbc"
   },
   "source": [
    "We will group 3 & 4, and 7-9 into a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb28fc755cb0c17712bf59a6c3c3f5aa76510d2d"
   },
   "outputs": [],
   "source": [
    "data_new = data.copy()\n",
    "data_new[\"quality\"] = 1*(data[\"quality\"] >= 3) + 1*(data[\"quality\"] >= 5) + 1*(data[\"quality\"] >= 6) + 1*(data[\"quality\"] >= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89fd049cfd67a81bfed818037469f3a6e088e851"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(data_new[\"quality\"], return_counts=True)\n",
    "print(\"New distribution of wine quality\")\n",
    "dict(zip(unique, counts*100.0/len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dabaec491835bd6adb2be9dae14484256f11f06e"
   },
   "source": [
    "Let's now try our algorithm on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "d86d3c1ccd506cccdd70270d82be280ef2cc6a99"
   },
   "outputs": [],
   "source": [
    "X_new, y_new = data.loc[:, data_new.columns != \"quality\"], data_new[\"quality\"]\n",
    "pred_new, conf_new, acc_new = logistic_regression(X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1dba99f2b49341d567473e9c9c4a2c29dd9a19d6"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of logistic regression after re-grouping quality:\", round(max(acc_new)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ede4b789d9fbcad544a3621795f582dd66746e8"
   },
   "source": [
    "No improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
