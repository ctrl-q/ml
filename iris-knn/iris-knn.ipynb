{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First ML project! Building a simple k-NN model & running it on the classic iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkowski distance between vectors and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_vec(x1,x2,p=2.0,axis=None):\n",
    "    return np.sum(\n",
    "        np.abs((x1-x2))**p\n",
    "        ,axis=axis\n",
    "    )**(1.0/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_mat(x,Y,p=2.0):\n",
    "    return minkowski_vec(x,Y,p,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(x, data, p=2): \n",
    "    feats = data[:,:-1] # remove last column (which is y)\n",
    "    dist = minkowski_mat(x, feats, p)\n",
    "    i = np.argmin(dist)\n",
    "    neighbor = data[i,-1]\n",
    "    return neighbor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running nn on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.0 % Accuracy\n"
     ]
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    training_size = min(100,int(len(data)*0.7))\n",
    "    testing_size = len(data) - training_size\n",
    "    shuffled_data = np.random.permutation(data)\n",
    "    return shuffled_data[:training_size],shuffled_data[training_size:]\n",
    "\n",
    "iris = np.loadtxt(\"iris.txt\")\n",
    "train,test = split_data(iris)\n",
    "\n",
    "def nn_performance(training_data,test_data):\n",
    "    accuracy = 0.0\n",
    "    for i in test_data:\n",
    "        truth = i[-1]\n",
    "        prediction = nn(i[:-1],training_data) \n",
    "        if truth == prediction:\n",
    "            accuracy += 1\n",
    "    return accuracy / len(test_data)\n",
    "\n",
    "# print(knn_performance(test,test)) # should be 1.0\n",
    "# print(knn_performance(train,train)) # should also be 1.0\n",
    "print(100 * nn_performance(train,test), \"% Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k for training dataset: 3 ; Accuracy: 0.96\n",
      "Best k for testing dataset: 7 ; Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "def knn(x, data, k, p=2): \n",
    "    feats = data[:,:-1] # remove last column (which is y)\n",
    "    dist = minkowski_mat(x, feats, p)\n",
    "    indices = np.argpartition(dist,range(k))[:k] # find indices of k-NN\n",
    "    neighbors = data[indices,-1] # get elements at those indices\n",
    "    classes,counts = np.unique(neighbors,return_counts=True) # frequency table for each class\n",
    "    winning_index = np.argmax(counts) # class with the highest frequency\n",
    "    return classes[winning_index]\n",
    "    \n",
    "def knn_performance(training_data,test_data,k):\n",
    "    accuracy = 0.0\n",
    "    for i in test_data:\n",
    "        truth = i[-1]\n",
    "        prediction = knn(i[:-1],training_data,k) \n",
    "        if truth == prediction:\n",
    "            accuracy += 1\n",
    "    return accuracy / len(test_data)\n",
    "\n",
    "def find_k(training_data,test_data,possible_ks = None):\n",
    "    if possible_ks == None:\n",
    "        possible_ks = range(len(training_data))\n",
    "    best_k = 0\n",
    "    best_performance = 0.0\n",
    "    for k in possible_ks:\n",
    "        if k > 0: # k has to be > 0\n",
    "            perf = knn_performance(training_data,test_data,k)\n",
    "            if perf > best_performance:\n",
    "                best_k = k\n",
    "                best_performance = perf\n",
    "    return best_k,best_performance\n",
    "\n",
    "train_k, train_perf = find_k(train,test)\n",
    "test_k, test_perf = find_k(test,train)\n",
    "print(\"Best k for training dataset:\", train_k, \"; Accuracy:\",train_perf)\n",
    "print(\"Best k for testing dataset:\", test_k, \"; Accuracy:\",test_perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28\n"
     ]
    }
   ],
   "source": [
    "print(knn_performance(train,test,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation: Since the training dataset has 100 elements, the 100 nearest neighbors are simply the entire dataset.\n",
    "          You therefore return the class that occurs the most often in the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1.0\n",
      "Frequency: 0.28\n",
      "Which is the same as the 100-NN performance\n"
     ]
    }
   ],
   "source": [
    "x = test[np.random.randint(len(test))][:-1] #pick a random row from test data and remove its class\n",
    "predicted_class = knn(x,train,100)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "classes,counts = np.unique(test[:,-1],return_counts=True) # frequency table for each class in test\n",
    "print(\"Frequency:\",counts[classes.tolist().index(predicted_class)]*1.0/len(test))\n",
    "print(\"Which is the same as the 100-NN performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
